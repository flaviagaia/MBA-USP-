{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa6a0d8c",
   "metadata": {
    "id": "uSq1bFOi-Hy7",
    "papermill": {
     "duration": 0.003471,
     "end_time": "2022-11-07T18:23:58.006428",
     "exception": false,
     "start_time": "2022-11-07T18:23:58.002957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color=\"red\"> MBA em IA e Big Data</font>\n",
    "## <span style=\"color:red\">Redes Neurais e Deep Learning</span>\n",
    "## **Exemplo de Uso de LSTM**\n",
    "\n",
    "### **REDES NEURAIS RECORRENTES com**\n",
    "### **VALIDAÇÃO CRUZADA**\n",
    "\n",
    "### Profa. Roseli Ap. Francelin Romero\n",
    "\n",
    "**PROBLEMA**: SERIE TEMPORAL - Previsão de passageiros de uma Cia Aérea Internacional.\n",
    "\n",
    "Este é um problema em que, dados um ano e um mês, a tarefa é prever o número de passageiros (x 1.000) de companhias aéreas internacionais. Os dados variam de janeiro de 1949 a dezembro de 1960,  12 anos, com 144 observações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e363cfb",
   "metadata": {
    "id": "9vnARAijFASq",
    "papermill": {
     "duration": 0.001955,
     "end_time": "2022-11-07T18:23:58.011003",
     "exception": false,
     "start_time": "2022-11-07T18:23:58.009048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Por default o Keras mantem um estado com um batch (stateful=True). Um batch é um no. de linhas do conjunto de dados usado para o treinamento. Entre uma camada e outra na LTSM o estado é desconsiderado (limpado) por default. Isto nos dá um controle mais fino entre os estados e podemos usar a função resetstates(). <\\br>\n",
    "\n",
    "**LSTM PARA REGRESSÃO** A cam. LSTM espera uma matriz como entrada: [samples, time steps, features], onde?\n",
    "\n",
    "**Samples**: são as observações do dominio da aplicação, normalmente as linhas do dataset.</br> \n",
    "**Time steps**: são passos de tempo de separação de uma dada variavel para uma dada observação.</br>\n",
    "**Features**: são medidas separadas observadas em cada tempo da observação.\n",
    "\n",
    "Nesta série, os seguintes passos serão considerados:\n",
    "\n",
    "- Carregar o dataset do CSV file.\n",
    "- Transformar o dataset de modo a adequa-lo para o modelo LSTM, incluindo: \n",
    "- 1 - Transformar os dados para um problema de aprendizado supervisionado. \n",
    "- 2 - Transformar os dados para ser \"stationary\". \n",
    "- 3 - Transformar os dados para que fiquem no interv. [-1,1]. \n",
    "- 4 - Ajusta o modelo da rede LSTM para o conj. de treinamento. \n",
    "- 5 - Avaliar o modelo LSTM estático no conjunto de teste. \n",
    "- 6 - Visualizar o desempenho da Previsão. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae716eb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:23:58.018220Z",
     "iopub.status.busy": "2022-11-07T18:23:58.017133Z",
     "iopub.status.idle": "2022-11-07T18:24:04.718255Z",
     "shell.execute_reply": "2022-11-07T18:24:04.717081Z"
    },
    "id": "sJckLNezjKIj",
    "papermill": {
     "duration": 6.707839,
     "end_time": "2022-11-07T18:24:04.721086",
     "exception": false,
     "start_time": "2022-11-07T18:23:58.013247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# LSTM for international airline passengers problem with regression framing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# converte um array de valores numa matriz de dados \n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):        \n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "# as sementes ajudam a ter resultados reproduzíveis\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(2)\n",
    "# Carregar o dataset\n",
    "dataframe = read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv', usecols=[1], engine='python')\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed56c5d",
   "metadata": {
    "id": "kAci9nseaml4",
    "papermill": {
     "duration": 0.002076,
     "end_time": "2022-11-07T18:24:04.725865",
     "exception": false,
     "start_time": "2022-11-07T18:24:04.723789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Codigo com modificações para separar e rodar o conjunto de dados com o TimeSerieSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f07e7bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:04.731864Z",
     "iopub.status.busy": "2022-11-07T18:24:04.731430Z",
     "iopub.status.idle": "2022-11-07T18:24:04.752941Z",
     "shell.execute_reply": "2022-11-07T18:24:04.751770Z"
    },
    "id": "SrKZ26nOazvM",
    "outputId": "c453093d-6c40-4dd8-c2da-9159d799231d",
    "papermill": {
     "duration": 0.027921,
     "end_time": "2022-11-07T18:24:04.755963",
     "exception": false,
     "start_time": "2022-11-07T18:24:04.728042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X(t) Y(t+1)\n",
      "[112.] 118.0\n",
      "[118.] 132.0\n",
      "[132.] 129.0\n",
      "[129.] 121.0\n",
      "[121.] 135.0\n",
      "[135.] 148.0\n",
      "[148.] 148.0\n",
      "[148.] 136.0\n",
      "[136.] 119.0\n",
      "[119.] 104.0\n",
      "[104.] 118.0\n",
      "[118.] 115.0\n",
      "[115.] 126.0\n",
      "[126.] 141.0\n",
      "[141.] 135.0\n",
      "[135.] 125.0\n",
      "[125.] 149.0\n",
      "[149.] 170.0\n",
      "[170.] 170.0\n",
      "[170.] 158.0\n",
      "[158.] 133.0\n",
      "[133.] 114.0\n",
      "[114.] 140.0\n",
      "[140.] 145.0\n",
      "[145.] 150.0\n",
      "[150.] 178.0\n",
      "[178.] 163.0\n",
      "[163.] 172.0\n",
      "[172.] 178.0\n",
      "[178.] 199.0\n",
      "[199.] 199.0\n",
      "[199.] 184.0\n",
      "[184.] 162.0\n",
      "[162.] 146.0\n",
      "[146.] 166.0\n",
      "[166.] 171.0\n",
      "[171.] 180.0\n",
      "[180.] 193.0\n",
      "[193.] 181.0\n",
      "[181.] 183.0\n",
      "[183.] 218.0\n",
      "[218.] 230.0\n",
      "[230.] 242.0\n",
      "[242.] 209.0\n",
      "[209.] 191.0\n",
      "[191.] 172.0\n",
      "[172.] 194.0\n",
      "[194.] 196.0\n",
      "[196.] 196.0\n",
      "[196.] 236.0\n",
      "[236.] 235.0\n",
      "[235.] 229.0\n",
      "[229.] 243.0\n",
      "[243.] 264.0\n",
      "[264.] 272.0\n",
      "[272.] 237.0\n",
      "[237.] 211.0\n",
      "[211.] 180.0\n",
      "[180.] 201.0\n",
      "[201.] 204.0\n",
      "[204.] 188.0\n",
      "[188.] 235.0\n",
      "[235.] 227.0\n",
      "[227.] 234.0\n",
      "[234.] 264.0\n",
      "[264.] 302.0\n",
      "[302.] 293.0\n",
      "[293.] 259.0\n",
      "[259.] 229.0\n",
      "[229.] 203.0\n",
      "[203.] 229.0\n",
      "[229.] 242.0\n",
      "[242.] 233.0\n",
      "[233.] 267.0\n",
      "[267.] 269.0\n",
      "[269.] 270.0\n",
      "[270.] 315.0\n",
      "[315.] 364.0\n",
      "[364.] 347.0\n",
      "[347.] 312.0\n",
      "[312.] 274.0\n",
      "[274.] 237.0\n",
      "[237.] 278.0\n",
      "[278.] 284.0\n",
      "[284.] 277.0\n",
      "[277.] 317.0\n",
      "[317.] 313.0\n",
      "[313.] 318.0\n",
      "[318.] 374.0\n",
      "[374.] 413.0\n",
      "[413.] 405.0\n",
      "[405.] 355.0\n",
      "[355.] 306.0\n",
      "[306.] 271.0\n",
      "[271.] 306.0\n",
      "[306.] 315.0\n",
      "[315.] 301.0\n",
      "[301.] 356.0\n",
      "[356.] 348.0\n",
      "[348.] 355.0\n",
      "[355.] 422.0\n",
      "[422.] 465.0\n",
      "[465.] 467.0\n",
      "[467.] 404.0\n",
      "[404.] 347.0\n",
      "[347.] 305.0\n",
      "[305.] 336.0\n",
      "[336.] 340.0\n",
      "[340.] 318.0\n",
      "[318.] 362.0\n",
      "[362.] 348.0\n",
      "[348.] 363.0\n",
      "[363.] 435.0\n",
      "[435.] 491.0\n",
      "[491.] 505.0\n",
      "[505.] 404.0\n",
      "[404.] 359.0\n",
      "[359.] 310.0\n",
      "[310.] 337.0\n",
      "[337.] 360.0\n",
      "[360.] 342.0\n",
      "[342.] 406.0\n",
      "[406.] 396.0\n",
      "[396.] 420.0\n",
      "[420.] 472.0\n",
      "[472.] 548.0\n",
      "[548.] 559.0\n",
      "[559.] 463.0\n",
      "[463.] 407.0\n",
      "[407.] 362.0\n",
      "[362.] 405.0\n",
      "[405.] 417.0\n",
      "[417.] 391.0\n",
      "[391.] 419.0\n",
      "[419.] 461.0\n",
      "[461.] 472.0\n",
      "[472.] 535.0\n",
      "[535.] 622.0\n",
      "[622.] 606.0\n",
      "[606.] 508.0\n",
      "[508.] 461.0\n",
      "[461.] 390.0\n"
     ]
    }
   ],
   "source": [
    "# reshape em X=t and Y=t+1\n",
    "look_back = 1\n",
    "X_dataset, Y_dataset = create_dataset(dataset, look_back)\n",
    "\n",
    "print('X(t)', 'Y(t+1)')\n",
    "for i in range(len(X_dataset)):\n",
    "    print(X_dataset[i], Y_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd50b6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:04.763294Z",
     "iopub.status.busy": "2022-11-07T18:24:04.762172Z",
     "iopub.status.idle": "2022-11-07T18:25:10.796615Z",
     "shell.execute_reply": "2022-11-07T18:25:10.795013Z"
    },
    "id": "2jTWHe-8a72I",
    "outputId": "3dceae1d-ead7-48a4-bca6-ea91dfb4d468",
    "papermill": {
     "duration": 66.041408,
     "end_time": "2022-11-07T18:25:10.800068",
     "exception": false,
     "start_time": "2022-11-07T18:24:04.758660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 18:24:04.829206: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2022-11-07 18:24:05.209290: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 2s 1ms/step - loss: 0.3404\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2988\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2639\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2343\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.2087\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1862\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1675\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1488\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1337\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1191\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.1077\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0962\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0881\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0811\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0750\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0708\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0678\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0652\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0631\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0615\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0607\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0595\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0588\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0583\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0575\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0575\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0566\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0564\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0557\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0552\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0545\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0541\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0539\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0529\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0530\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0522\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0517\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0513\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0508\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0504\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0501\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0494\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0491\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0488\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0482\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0480\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0473\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0474\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0466\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0464\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0460\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0455\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0451\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0447\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0445\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0440\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0436\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0435\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0434\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0427\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0423\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0421\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0418\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0416\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0411\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0408\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0405\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0402\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0401\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0397\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0394\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0393\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0391\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0387\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0385\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0384\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0381\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0379\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0377\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0384\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0378\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0370\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0368\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0368\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0369\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0365\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0365\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0363\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0362\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0360\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0360\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0356\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0354\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0353\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0353\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0352\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0350\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0352\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0349\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.0348\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train Score: 13.75 RMSE\n",
      "Test Score: 32.57 RMSE\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 2s 1ms/step - loss: 0.2906\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.2184\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1641\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.1246\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0957\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0771\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0655\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0582\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0542\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0519\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0496\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0482\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0467\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0457\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0443\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0432\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0420\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0407\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0399\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0385\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0374\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0365\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0354\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0345\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0336\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0327\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0317\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0308\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0302\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0291\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0282\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0274\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0269\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0260\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0254\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0247\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0221\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0214\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0193\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.0189\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0184\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0179\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0176\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0169\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0166\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0161\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0157\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0155\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0152\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0148\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0147\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0145\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0143\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0142\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0140\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0138\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0134\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0137\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0139\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0135\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train Score: 15.93 RMSE\n",
      "Test Score: 22.94 RMSE\n",
      "Epoch 1/100\n",
      "73/73 [==============================] - 2s 1ms/step - loss: 0.1223\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0641\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0365\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0274\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0250\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0232\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0215\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0185\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0171\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0158\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0136\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0126\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0121\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0116\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0107\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0102\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0101\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0097\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0093\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0092\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0091\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0091\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0091\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 81/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 82/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 83/100\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 84/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 85/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 86/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 87/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 88/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 89/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 90/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 91/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 92/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0090\n",
      "Epoch 93/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Epoch 94/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 95/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 96/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 97/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0087\n",
      "Epoch 98/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 99/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0089\n",
      "Epoch 100/100\n",
      "73/73 [==============================] - 0s 1ms/step - loss: 0.0088\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train Score: 18.34 RMSE\n",
      "Test Score: 38.34 RMSE\n",
      "Epoch 1/100\n",
      "96/96 [==============================] - 2s 1ms/step - loss: 0.1852\n",
      "Epoch 2/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.1114\n",
      "Epoch 3/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0707\n",
      "Epoch 4/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0517\n",
      "Epoch 5/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0437\n",
      "Epoch 6/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0397\n",
      "Epoch 7/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0361\n",
      "Epoch 8/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0327\n",
      "Epoch 9/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0292\n",
      "Epoch 10/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0253\n",
      "Epoch 11/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0216\n",
      "Epoch 12/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0178\n",
      "Epoch 13/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0146\n",
      "Epoch 14/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0119\n",
      "Epoch 15/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0096\n",
      "Epoch 16/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0081\n",
      "Epoch 17/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0070\n",
      "Epoch 18/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0064\n",
      "Epoch 19/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0060\n",
      "Epoch 20/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0058\n",
      "Epoch 21/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 22/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 23/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 24/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 25/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 26/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 27/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 28/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 29/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 30/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 31/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 32/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 33/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 34/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 35/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 36/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 37/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 38/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 39/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 40/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 41/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 42/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 43/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 44/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 45/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 46/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 47/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 48/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 49/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 50/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0055\n",
      "Epoch 51/100\n",
      "96/96 [==============================] - 0s 2ms/step - loss: 0.0056\n",
      "Epoch 52/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 53/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 54/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 55/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 56/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 57/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 58/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 59/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 60/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 61/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 62/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 63/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 64/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 65/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 66/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 67/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 68/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 69/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 70/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 71/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 72/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 73/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 74/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 75/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 76/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 77/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 78/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 79/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 80/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 81/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 82/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 83/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 84/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 85/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 86/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 87/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 88/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 89/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 90/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 91/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 92/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 93/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 94/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 95/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 96/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 97/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 98/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0056\n",
      "Epoch 99/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0055\n",
      "Epoch 100/100\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train Score: 22.63 RMSE\n",
      "Test Score: 44.16 RMSE\n",
      "Epoch 1/100\n",
      "119/119 [==============================] - 2s 1ms/step - loss: 0.0577\n",
      "Epoch 2/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0239\n",
      "Epoch 3/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0173\n",
      "Epoch 4/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0144\n",
      "Epoch 5/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0119\n",
      "Epoch 6/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0098\n",
      "Epoch 7/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0082\n",
      "Epoch 8/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0070\n",
      "Epoch 9/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0063\n",
      "Epoch 10/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0057\n",
      "Epoch 11/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 12/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0052\n",
      "Epoch 13/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 14/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 15/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 16/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 17/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 18/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 19/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 20/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 21/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 22/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0054\n",
      "Epoch 23/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 24/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 25/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 26/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 27/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 28/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 29/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 30/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 31/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 32/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 33/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 34/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 35/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 36/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 37/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0052\n",
      "Epoch 38/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 39/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 40/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 41/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 42/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 43/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 44/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 45/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 46/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 47/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 48/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 49/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 50/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 51/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 52/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 53/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 54/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 55/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 56/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 57/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 58/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 59/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 60/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 61/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 62/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 63/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 64/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 65/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0048\n",
      "Epoch 66/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 67/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 68/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 69/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 70/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 71/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 72/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 73/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 74/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 75/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 76/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 77/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 78/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 79/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 80/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0051\n",
      "Epoch 81/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 82/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0049\n",
      "Epoch 83/100\n",
      "119/119 [==============================] - 0s 2ms/step - loss: 0.0050\n",
      "Epoch 84/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 85/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 86/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 87/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 88/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 89/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 90/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 91/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 92/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 93/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 94/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 95/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 96/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 97/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 98/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Epoch 99/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0049\n",
      "Epoch 100/100\n",
      "119/119 [==============================] - 0s 1ms/step - loss: 0.0050\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 4)                 96        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train Score: 27.88 RMSE\n",
      "Test Score: 54.90 RMSE\n",
      "Resultados\n",
      " A media no Conjunto de Treinamento nos 5 folds foi de 15.423017\n",
      " A media no Conjunto de Test nos 5 folds foi de 31.152652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)\n",
    "i = 1\n",
    "score = []\n",
    "sum_Train_Error =0\n",
    "sum_Test_Error = 0\n",
    "for tr_index, val_index in tscv.split(X_dataset):\n",
    "    X_tr, X_val = X_dataset[tr_index], X_dataset[val_index]\n",
    "    y_tr, y_val = Y_dataset[tr_index], Y_dataset[val_index]\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    #Fit apenas no conjunto de treino\n",
    "    X_tr = scaler.fit_transform(X=X_tr)\n",
    "    y_tr = scaler.transform(y_tr.reshape(-1, 1))\n",
    "    #No conjunto de treino, apenas aplica o fit obtido no conjunto de treino \n",
    "    X_val = scaler.transform(X=X_val)\n",
    "    y_val = scaler.transform(y_val.reshape(-1, 1))\n",
    "\n",
    "    #print(\"TRAIN:\", tr_index, \"TEST:\", val_index)\n",
    "    #print(\"TrainX:\", X_tr, \"TrainY:\", y_tr)\n",
    "    # reshape entrada na forma [samples, time steps, features]\n",
    "    trainX = np.reshape(X_tr, (X_tr.shape[0], 1, X_tr.shape[1]))\n",
    "    testX = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "    # criando and fit the LSTM network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(trainX, y_tr, epochs=100, batch_size=1, verbose=\"auto\")\n",
    "    # model.score(testX,y_val)\n",
    "    model.summary()\n",
    "    # fazer as predicoes\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "    # inverter antes as predicoes\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform(y_tr)\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform(y_val)\n",
    "\n",
    "    # calcular o RMSE error root mean squared error\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "    sum_Train_Error += trainScore\n",
    "    sum_Test_Error += testScore\n",
    "    i += 1\n",
    "\n",
    "print(\"Resultados\")\n",
    "print(\" A media no Conjunto de Treinamento nos %d folds foi de %f\" % (i-1, sum_Train_Error/i-1)) \n",
    "print(\" A media no Conjunto de Test nos %d folds foi de %f\" % (i-1, sum_Test_Error/i-1))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc10ae",
   "metadata": {
    "id": "l9Hn6tS_dSJi",
    "papermill": {
     "duration": 0.109011,
     "end_time": "2022-11-07T18:25:11.023196",
     "exception": false,
     "start_time": "2022-11-07T18:25:10.914185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Podemos ver que em media obtemos um erro aproximado de 15 passageiros (em milhares) no conj. de treino e um erro aproximado de 30 pasageiros (em milhares) no conj. de teste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 85.849673,
   "end_time": "2022-11-07T18:25:14.723364",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-07T18:23:48.873691",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
