{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587d5192",
   "metadata": {
    "id": "uSq1bFOi-Hy7",
    "papermill": {
     "duration": 0.008078,
     "end_time": "2022-11-07T18:17:12.198704",
     "exception": false,
     "start_time": "2022-11-07T18:17:12.190626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color=\"red\"> MBA em IA e Big Data</font>\n",
    "## <span style=\"color:red\">Redes Neurais e Deep Learning</span>\n",
    " \n",
    "### **REDES NEURAIS RECORRENTES - LSTM e GRU**\n",
    "### Profa. Roseli Ap. Francelin Romero\n",
    "\n",
    "**PROBLEMA**: SERIE TEMPORAL - Previsão de IPC no periodo 2016.\n",
    "\n",
    "Este é um problema em que, dados um ano e um mês, a tarefa é prever o IPC (Alimentacao_Vestuario) nos anos de 2016 a 2021. Os dados variam de fev/2016 a set/2021, com 68 observações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543fef0",
   "metadata": {
    "id": "9vnARAijFASq",
    "papermill": {
     "duration": 0.004277,
     "end_time": "2022-11-07T18:17:12.207797",
     "exception": false,
     "start_time": "2022-11-07T18:17:12.203520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**LSTM PARA REGRESSÃO** A cam. LSTM espera uma matriz como entrada: [samples, time steps, features], onde?\n",
    "\n",
    "**Samples**: são as observações do dominio da aplicação, normalmente as linhas do dataset.</br> \n",
    "**Time steps**: são passos de tempo de separação de uma dada variavel para uma dada observação.</br>\n",
    "**Features**: são medidas separadas observadas em cada tempo da observação.\n",
    "\n",
    " Será apenas a previsão de passo = 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "700897d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:17:12.221767Z",
     "iopub.status.busy": "2022-11-07T18:17:12.221100Z",
     "iopub.status.idle": "2022-11-07T18:17:20.226752Z",
     "shell.execute_reply": "2022-11-07T18:17:20.225649Z"
    },
    "id": "sJckLNezjKIj",
    "papermill": {
     "duration": 8.017412,
     "end_time": "2022-11-07T18:17:20.229764",
     "exception": false,
     "start_time": "2022-11-07T18:17:12.212352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# LSTM for IPC problem with regression framing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "\n",
    "# converte um array de valores numa matriz de dados \n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 0])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748ee6c2",
   "metadata": {
    "id": "lT6CP61PKrdf",
    "papermill": {
     "duration": 0.005072,
     "end_time": "2022-11-07T18:17:20.240171",
     "exception": false,
     "start_time": "2022-11-07T18:17:20.235099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1 - Fixar a semente de geração e Carregar o dataset do CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4698549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:17:20.253127Z",
     "iopub.status.busy": "2022-11-07T18:17:20.251695Z",
     "iopub.status.idle": "2022-11-07T18:17:21.008578Z",
     "shell.execute_reply": "2022-11-07T18:17:21.007018Z"
    },
    "id": "yERZM04wK3r2",
    "outputId": "e26bd1a4-f853-403a-f5f4-9bcdce3b0398",
    "papermill": {
     "duration": 0.764976,
     "end_time": "2022-11-07T18:17:21.010358",
     "exception": true,
     "start_time": "2022-11-07T18:17:20.245382",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.utils' has no attribute 'set_random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/2606730577.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fixar a semente para geração de nos. aleatórios\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Carregar o dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IPC.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.utils' has no attribute 'set_random_seed'"
     ]
    }
   ],
   "source": [
    "# fixar a semente para geração de nos. aleatórios\n",
    "keras.utils.set_random_seed(7) \n",
    "# Carregar o dataset\n",
    "dataframe = read_csv('IPC.csv', index_col=0)\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53d8e1",
   "metadata": {
    "id": "hDIJrQ9eLdnl",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "2 - Como temos dados negativos, normalizar os dados no intervalo [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f79d9",
   "metadata": {
    "id": "dtwLIpiFDU-t",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalizar o dataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b90904",
   "metadata": {
    "id": "ApoB0Y37LqmQ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "3 - Separar os dados em treinamento (67%) e teste (33%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc80ba",
   "metadata": {
    "id": "GOkjXAikDVW5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dividir em conjuntos de train and test \n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ddd61",
   "metadata": {
    "id": "1xkRTVjsMYIk",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "6 - Modelar os dados com a LSTM, com timestep = 1, adotando 2 abordagens comparativas:\n",
    " - LSTM com 04 neuronios e 100 épocas\n",
    " - LSTM com 04 neuronios e 1000 épocas\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553bf91b",
   "metadata": {
    "id": "1-jh_lLHDVuh",
    "outputId": "9af1a941-5556-4b01-ef50-7abfa88e11da",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reshape em X=t and Y=t+1\n",
    "#Colocar os dados na forma: X(t) e Y(t+1), chamando a funçao create\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#print('X(t)', 'Y(t+1)')\n",
    "#for i in range(len(trainX)):\n",
    "#  print(trainX[i], trainY[i])\n",
    "\n",
    "# reshape entrada na forma [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# criando and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "model.summary()\n",
    "# fazer as predicoes\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# inverter antes as predicoes\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "# calcular o RMSE error root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0b6320",
   "metadata": {
    "id": "xjtv8-OT8fJ7",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "7 - Fazer o plot da previsão, lembrando que é necessário retornar os dados para a forma original. O que se pode observar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075ce72d",
   "metadata": {
    "id": "srX5yGaEDWJc",
    "outputId": "7ead143a-cd97-4c39-f004-cd48b0d8a381",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset), color=\"blue\")\n",
    "plt.plot(trainPredictPlot, color=\"green\")\n",
    "plt.plot(testPredictPlot, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b12a24",
   "metadata": {
    "id": "T2U1gEZJDWcW",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Podemos ver que o modelo LSTM com mais épocas se ajusta melhor nos dados de treino mas nao consegue generalizar bem no conjunto de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eded4a7",
   "metadata": {
    "id": "aLWb2aZPFJm3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "8 - Modelar os dados com a GRU, com timestep = 1, adotando 2 abordagens comparativas:\n",
    " - LSTM com 04 neuronios e 100 épocas\n",
    " - LSTM com 04 neuronios e 1000 épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a0128",
   "metadata": {
    "id": "MxCTodO3wMg_",
    "outputId": "4bac9971-2c79-4097-d65c-d24bbfb9b152",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Novo codigo para GRU\n",
    " \n",
    "\n",
    "# reshape em X=t and Y=t+1\n",
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "#print('X(t)', 'Y(t+1)')\n",
    "#for i in range(len(trainX)):\n",
    "#  print(trainX[i], trainY[i])\n",
    "# reshape entrada na forma [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "# criando and fit a rede GRU\n",
    "model2 = Sequential()\n",
    "model2.add(GRU(4, input_shape=(1, look_back)))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model2.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)\n",
    "model2.summary()\n",
    "# fazer as predicoes\n",
    "trainPredict2 = model2.predict(trainX)\n",
    "testPredict2 = model2.predict(testX)\n",
    "# inverter antes as predicoes\n",
    "trainPredict2 = scaler.inverse_transform(trainPredict2)\n",
    "trainY2 = scaler.inverse_transform([trainY])\n",
    "testPredict2 = scaler.inverse_transform(testPredict2)\n",
    "testY2 = scaler.inverse_transform([testY])\n",
    "# calcular o RMSE error root mean squared error\n",
    "trainScore2 = math.sqrt(mean_squared_error(trainY2[0], trainPredict2[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore2))\n",
    "testScore2 = math.sqrt(mean_squared_error(testY2[0], testPredict2[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f8f79",
   "metadata": {
    "id": "T6s1dtijD6FE",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "9 - Fazer o plot da previsão da GRU, lembrando que é necessário retornar os dados para a forma original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eceefa",
   "metadata": {
    "id": "gPf1bcbnD6fE",
    "outputId": "5cbb6238-a618-4519-afed-d84f6354e808",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset), color=\"blue\")\n",
    "plt.plot(trainPredictPlot, color=\"green\")\n",
    "plt.plot(testPredictPlot, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac3b5e5",
   "metadata": {
    "id": "Wu2eSCc-__DZ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "10- Estabeleça uma comparação entre a LSTM e a GRU.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd12a49",
   "metadata": {
    "id": "7HHe01TYAuz-",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Resp. Podemos ver que o modelo LSTM com mais épocas se ajusta melhor nos dados de treino mas nao consegue generalizar bem no conjunto de teste. O mesmo acontece com a rede GRU. Observa também que o modelo GRU apresentou  performances similares no conjunto de treinamento que a LSTM, tanto com 100 quanto com 1000 épocas. A série é muito instável e é necessário tentar outras abordagens para obter uma previsão melhor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd25b3",
   "metadata": {
    "id": "Qc13TmbHUhcI",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.223695,
   "end_time": "2022-11-07T18:17:24.242621",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-07T18:17:03.018926",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
