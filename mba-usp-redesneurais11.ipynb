{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec553d3",
   "metadata": {
    "id": "xsStgDrgfZGy",
    "papermill": {
     "duration": 0.004313,
     "end_time": "2022-11-07T18:24:30.346212",
     "exception": false,
     "start_time": "2022-11-07T18:24:30.341899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <font color=\"red\"> MBA em IA e Big Data</font>\n",
    "## <span style=\"color:red\">Redes Neurais e Aprendizado Profundo</sp>\n",
    "\n",
    "#Profa. Roseli Ap. Francelin Romero </br>\n",
    "\n",
    "**Exemplo de Rede Neural com Aprendizado por Reforço**  para\n",
    "resolver o Problema FrozenLake-v1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929c24f6",
   "metadata": {
    "id": "nXP0X3SBfAPs",
    "papermill": {
     "duration": 0.002709,
     "end_time": "2022-11-07T18:24:30.352160",
     "exception": false,
     "start_time": "2022-11-07T18:24:30.349451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Problema FrozenLake-v1**\n",
    "O agente controla o movimento de um personagem em um grid (grade - forma matricial). Alguns blocos da grade podem ser percorridos, e outros fazem com que o agente caia na água. Além disso, a direção do movimento do agente é incerta e depende apenas parcialmente da direção escolhida. \n",
    "O agente é recompensado por encontrar um caminho percorrível até um bloco de meta. Um exemplo para uma grade 4x4 é mostrado abaixo:\n",
    "\n",
    "\n",
    "SFFF       (S: starting point, safe) </br>\n",
    "FHFH       (F: frozen surface, safe) </br>\n",
    "FFFH       (H: hole, cai no buraco) </br>\n",
    "HFFG       (G: goal, onde frisbee (disco) é localizado) </br>\n",
    "\n",
    "O episódio termina se o agente encontra o alvo ou cai no buraco. Ao encontrar o alvo, ele recebe 1. Caso contrário, recebe 0.\n",
    "\n",
    "No exemplo abaixo vamos trabalhar com um Grid de tamanho: 8x8 </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d079059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:30.360197Z",
     "iopub.status.busy": "2022-11-07T18:24:30.359556Z",
     "iopub.status.idle": "2022-11-07T18:24:36.380274Z",
     "shell.execute_reply": "2022-11-07T18:24:36.379033Z"
    },
    "executionInfo": {
     "elapsed": 8040,
     "status": "ok",
     "timestamp": 1667262243495,
     "user": {
      "displayName": "Roseli Aparecida Francelin Romero",
      "userId": "04295547795514221387"
     },
     "user_tz": 180
    },
    "id": "FxMDNSi7fSTA",
    "papermill": {
     "duration": 6.028286,
     "end_time": "2022-11-07T18:24:36.383317",
     "exception": false,
     "start_time": "2022-11-07T18:24:30.355031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40d1e4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T18:24:36.392642Z",
     "iopub.status.busy": "2022-11-07T18:24:36.391697Z",
     "iopub.status.idle": "2022-11-07T18:24:37.762370Z",
     "shell.execute_reply": "2022-11-07T18:24:37.760621Z"
    },
    "executionInfo": {
     "elapsed": 266,
     "status": "ok",
     "timestamp": 1667262246835,
     "user": {
      "displayName": "Roseli Aparecida Francelin Romero",
      "userId": "04295547795514221387"
     },
     "user_tz": 180
    },
    "id": "ozZZUuWMkasL",
    "papermill": {
     "duration": 1.378175,
     "end_time": "2022-11-07T18:24:37.764834",
     "exception": true,
     "start_time": "2022-11-07T18:24:36.386659",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.utils' has no attribute 'set_random_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/3801440748.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.utils' has no attribute 'set_random_seed'"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e170b086",
   "metadata": {
    "executionInfo": {
     "elapsed": 286,
     "status": "ok",
     "timestamp": 1667262249049,
     "user": {
      "displayName": "Roseli Aparecida Francelin Romero",
      "userId": "04295547795514221387"
     },
     "user_tz": 180
    },
    "id": "GhPSx-Wk1tm_",
    "outputId": "9fe8688d-b257-48c5-da32-96e3d243f642",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v1')  # definindo o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc1567",
   "metadata": {
    "executionInfo": {
     "elapsed": 262,
     "status": "ok",
     "timestamp": 1667262252477,
     "user": {
      "displayName": "Roseli Aparecida Francelin Romero",
      "userId": "04295547795514221387"
     },
     "user_tz": 180
    },
    "id": "lwmT4P4v4AHQ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c507a1d",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1667262253943,
     "user": {
      "displayName": "Roseli Aparecida Francelin Romero",
      "userId": "04295547795514221387"
     },
     "user_tz": 180
    },
    "id": "0w8RjixP16qY",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()     # vai considerar vantagens de aceleracao\n",
    "#Passo feed-forward na rede rasa usada para escolher ações\n",
    "inputs1 = tf.compat.v1.placeholder(dtype=tf.float32,shape=(1,64))\n",
    "W = tf.Variable(tf.random.uniform([64,4],0,0.01))\n",
    "Qout = tf.matmul(inputs1,W)\n",
    "predict = tf.argmax(Qout,1)\n",
    "\n",
    "#Definição da função loss (perda) calculando o MSE entre o alvo e os valores Q preditos.\n",
    "nextQ = tf.compat.v1.placeholder(dtype=tf.float32, shape=(1,4))\n",
    "loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "trainer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "updateModel = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce558d",
   "metadata": {
    "id": "zHy3hWno2om3",
    "outputId": "0b45dd2d-20a7-4196-f79c-1dafbce8e54e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "init = tf.compat.v1.initialize_all_variables()\n",
    " \n",
    "# Set learning parameters\n",
    "y = .99\n",
    "e = 0.1\n",
    "max_episode_length = 199\n",
    "max_num_episodes = 2000\n",
    "#Criando a lista que contem o total de recompensas e steps per episode\n",
    "rList = []\n",
    "#Armazena a media das recompensas da ultima 'window_size' dos episodios\n",
    "average_ep_rewards = []\n",
    "window_size = 50\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(max_num_episodes):\n",
    "        #Reseta o ambiente e inicializa com novas observacoes\n",
    "        s = env.reset()\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0        \n",
    "        #Definindo a Q-Network\n",
    "        while j < max_episode_length:\n",
    "            j+=1\n",
    "            #Escolhe uma acao aleatoria (com e chance de acao aleatória) para a Q-network\n",
    "            a,allQ = sess.run([predict,Qout],feed_dict={inputs1:np.identity(64)[s:s+1]})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = env.action_space.sample()\n",
    "            #Vai para o novo estado do ambiente e pega a recompensa\n",
    "            s1,r,d,_ = env.step(a[0])\n",
    "            #Obtem os valores Q' alimentando o novo estado através da rede\n",
    "            Q1 = sess.run(Qout,feed_dict={inputs1:np.identity(64)[s1:s1+1]})\n",
    "            #Obtain maxQ' and set our target value for chosen action.\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0,a[0]] = r + y*maxQ1\n",
    "            #Treina a rede usando target and predicted Q values\n",
    "            _,W1 = sess.run([updateModel,W],feed_dict={inputs1:np.identity(64)[s:s+1],nextQ:targetQ})\n",
    "            #Adding the returns\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            if d == True:\n",
    "                #Reduz a chance de acao aleatoria durante o treinamento do modelo.\n",
    "                e = 1./((i/50) + 10)\n",
    "                break    \n",
    "        rList.append(rAll)        \n",
    "        if ((i+1) % window_size) == 0:          \n",
    "          avg = np.mean(rList[-window_size:])\n",
    "          print(f'Current episode no = {i}. Last {window_size} episodes mean reward = {avg}')\n",
    "          average_ep_rewards.append(avg)\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9af42b",
   "metadata": {
    "id": "PiVmo3Oc2wt2",
    "outputId": "36625950-be56-480c-8958-8810a0a92f2b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(average_ep_rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.177187,
   "end_time": "2022-11-07T18:24:40.903752",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-07T18:24:21.726565",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
