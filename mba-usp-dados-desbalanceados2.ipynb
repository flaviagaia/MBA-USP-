{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a234d99b",
   "metadata": {
    "id": "HaabIE4ETRhY",
    "papermill": {
     "duration": 0.005106,
     "end_time": "2022-10-01T12:05:05.780246",
     "exception": false,
     "start_time": "2022-10-01T12:05:05.775140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###**MBA em IA E BIGDATA**\n",
    "###**CURSO 2 - AM, CD E DM**\n",
    "### **PROFA. ROSELI A. F. ROMERO**\n",
    "\n",
    "##  **Dados desbalanceados**\n",
    "#**OBJETIVOS**:\n",
    "#- ABORDAGEM UNDERSAMPLING\n",
    "#- ABORDAGEM OVERSAMPLING\n",
    "#- ABORDAGEM HÍBRIDA \n",
    "---\n",
    "\n",
    "#No dataset que será utilizado nesse exercício, cada elemento representa uma transação com cartões de crédito. \n",
    "\n",
    "#A base possui 30 atributos. `Time` representa o tempo em segundos desde a primeira transação da base. `Amount` corresponde ao valor da transação.\n",
    "\n",
    "#Outros 28 atributos numéricos anonimizados também são fornecidos, com 1 variável (`Class`) de saída onde 1 significa fraude e 0 transação normal.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196d714",
   "metadata": {
    "id": "_YGNezFvvnES",
    "papermill": {
     "duration": 0.003612,
     "end_time": "2022-10-01T12:05:05.787999",
     "exception": false,
     "start_time": "2022-10-01T12:05:05.784387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###**Questão 01**.\n",
    "#Carregue o dataset `creditcard_sampled.csv` e mostre a distribuição das classes:\n",
    "\n",
    "*   Via histograma\n",
    "*   Exibindo o número de ocorrências de cada classe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c97d27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-01T12:05:05.799193Z",
     "iopub.status.busy": "2022-10-01T12:05:05.798193Z",
     "iopub.status.idle": "2022-10-01T12:05:05.813552Z",
     "shell.execute_reply": "2022-10-01T12:05:05.810238Z"
    },
    "id": "jrUONCLc3DEx",
    "papermill": {
     "duration": 0.024382,
     "end_time": "2022-10-01T12:05:05.816183",
     "exception": false,
     "start_time": "2022-10-01T12:05:05.791801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f7d341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-01T12:05:05.826738Z",
     "iopub.status.busy": "2022-10-01T12:05:05.826047Z",
     "iopub.status.idle": "2022-10-01T12:05:05.916041Z",
     "shell.execute_reply": "2022-10-01T12:05:05.914303Z"
    },
    "id": "8_mKl4wJ3UfK",
    "outputId": "95c65c56-c29c-4429-e412-5dab9991750e",
    "papermill": {
     "duration": 0.098015,
     "end_time": "2022-10-01T12:05:05.918273",
     "exception": true,
     "start_time": "2022-10-01T12:05:05.820258",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'creditcard_sampled.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19/3153898515.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'creditcard_sampled.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdados\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'creditcard_sampled.csv'"
     ]
    }
   ],
   "source": [
    "dados = pd.read_csv('creditcard_sampled.csv', index_col=0)\n",
    "dados.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b236c",
   "metadata": {
    "id": "E4250_AdU4Em",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#Usar a função describe() para obter: media, desvio e os quartis. Mais uma opção para o cálculo destes valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935fa6b6",
   "metadata": {
    "id": "HYuiyj4RsWOW",
    "outputId": "0e9d3d6a-a4f2-473f-c35d-4a6971ab4ed8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dados.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83dfb0d",
   "metadata": {
    "id": "cKHE8fUuVKwG",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Cálculo do Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177cbd1",
   "metadata": {
    "id": "fjcUtnuZ48aj",
    "outputId": "0ad9236f-d7cc-4942-9934-f80affeadea3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dados.hist('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb620d",
   "metadata": {
    "id": "07GCeQqi4_pr",
    "outputId": "6e4580e7-6b77-4bcc-d3d7-f2880ecc411f",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dados['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4d1841",
   "metadata": {
    "id": "Gx86EFEVfTHL",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Questão 02**.\n",
    "\n",
    "#Separe o conjunto de dados em variáveis de entrada e variável alvo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9b702",
   "metadata": {
    "id": "qpLjIsGMzUEU",
    "outputId": "25cc9aaf-79cf-440d-9b26-b7d17751cee2",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = dados.iloc[:, :-1].to_numpy()\n",
    "targets = dados.iloc[:, -1].to_numpy()\n",
    "\n",
    "print(np.bincount(targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d62cd49",
   "metadata": {
    "id": "ITDds1CcO7M9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Questão 03**.\n",
    "\n",
    "#Crie uma função que aplique a técnica de subamostragem aleatória nesse conjunto de dados. \n",
    "#- Sua função deve receber como entrada a base normalizada e as classes.\n",
    "\n",
    "#- Sua função e deve retornar um novo conjunto onde todas as classes devem ter o número de ocorrências da classe com **menor representatividade no conjunto de dados inicial** e um array com as respectivas labels.\n",
    "#- Mostre o resultado plotando um histograma da distribuição resultante classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e824d91",
   "metadata": {
    "id": "SU636BmTJzup",
    "outputId": "a1410556-6dd4-4895-b214-b217950279dd",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def undersample(inputs, targets):\n",
    "  # Separando os ids dos elementos que pertecem à cada classe\n",
    "  classe_0_ids = np.where(targets == 0)[0]\n",
    "  classe_1_ids = np.where(targets == 1)[0]\n",
    "\n",
    "  # Guardando quantos elementos temos em cada classe\n",
    "  tamanhos_classes = [len(x) for x in [classe_0_ids, classe_1_ids]]\n",
    "  menor_classe = np.min(tamanhos_classes)\n",
    "\n",
    "  # Usando numpy para fazer amostragem aleatória sem repetição (replace=false), selecionando o nro de elementos da menor classe\n",
    "  # Assim teremos todos os elementos da menor classe e o mesmo nro da maior\n",
    "  classe_0_sampled_ids = np.random.choice(classe_0_ids, size=menor_classe, replace=False)\n",
    "  classe_1_sampled_ids = np.random.choice(classe_1_ids, size=menor_classe, replace=False)\n",
    "  \n",
    "  # Até agora estávamos apenas operando nos IDs agora vamos pegar os elementos selecionados no inputs\n",
    "  undersampled_data = np.concatenate([inputs[classe_0_sampled_ids],\n",
    "                                 inputs[classe_1_sampled_ids]])\n",
    "  # O mesmo é feito para o target\n",
    "  undersampled_targets = np.concatenate([targets [classe_0_sampled_ids],\n",
    "                                      targets [classe_1_sampled_ids]])\n",
    "  return undersampled_data, undersampled_targets\n",
    "\n",
    "undersampled_data, undersampled_targets = undersample(inputs, targets)\n",
    "plt.hist(undersampled_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e2662",
   "metadata": {
    "id": "iJxBcsRMSEW4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Questão 04**.\n",
    "\n",
    "#Crie uma função que aplique a técnica de superamostragem aleatória nesse conjunto de dados. \n",
    "\n",
    "#- Sua função deve receber como entrada a base normalizada e as classes.\n",
    "\n",
    "#- Sua função deve receber como entrada a base original e retornar um novo conjunto de dados onde todas as classes devem ter o número de ocorrências da classe com **maior representatividade no conjunto de dados inicial** e um array com as respectivas labels.\n",
    "#- Mostre o resultado plotando um histograma da distribuição resultante classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b0a8dd",
   "metadata": {
    "id": "D5ElKqy5Kzvs",
    "outputId": "05704430-46dd-438f-b49f-1a26ea7e37ed",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def oversample(inputs, targets):\n",
    "  # Separando os ids dos elementos que pertecem à cada classe\n",
    "  classe_0_ids = np.where(targets == 0)[0]\n",
    "  classe_1_ids = np.where(targets == 1)[0]\n",
    "\n",
    "  # Computando o nro de elementos de cada classe e definindo o nro de elementos\n",
    "  # da classe majoritária\n",
    "  tamanhos_classes = [len(x) for x in [classe_0_ids, classe_1_ids]]\n",
    "  maior_classe = np.max(tamanhos_classes)\n",
    "\n",
    "  # Se tivermos menos elementos do que a maior classe, estamos trabalhando na classe minoritária\n",
    "  # Assim, queremos fazer oversample (replace=True) para aumentar o nro de elementos\n",
    "  replace = False\n",
    "  if tamanhos_classes[0] < maior_classe:\n",
    "    replace = True\n",
    "  classe_0_sampled_ids = np.random.choice(classe_0_ids, size=maior_classe, replace=replace)\n",
    "  \n",
    "  # Da mesma forma para a segunda classe\n",
    "  replace = False\n",
    "  if tamanhos_classes[1] < maior_classe:\n",
    "    replace = True\n",
    "  classe_1_sampled_ids = np.random.choice(classe_1_ids, size=maior_classe, replace=replace)\n",
    "\n",
    "  # Até agora estávamos apenas operando nos IDs agora vamos pegar os elementos selecionados no inputs\n",
    "  oversampled_data = np.concatenate([inputs[classe_0_sampled_ids],\n",
    "                                 inputs[classe_1_sampled_ids]])\n",
    "  # O mesmo é feito com o target\n",
    "  oversampled_targets = np.concatenate([targets [classe_0_sampled_ids],\n",
    "                                      targets [classe_1_sampled_ids]])\n",
    "  return oversampled_data, oversampled_targets\n",
    "\n",
    "oversampled_data, oversampled_targets = oversample(inputs, targets)\n",
    "plt.hist(oversampled_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f8fa4",
   "metadata": {
    "id": "7dIPsLCbSRNk",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### **Questão 05**.\n",
    "\n",
    "#Crie uma função que utilize técnicas de subamostragem e superamostragem nesse conjunto de dados para balancear o número de exemplos de cada classe.\n",
    "\n",
    "#- Sua função deve receber como entrada a base normalizada e as classes.\n",
    "#- Sua função deve receber como entrada a base original e retornar uma nova base onde todas as classes devem ter o número de ocorrências **igual à $\\frac{tamanho\\_dataset}{3}$** e um array com as respectivas labels.\n",
    "#- Mostre o resultado plotando um histograma da distribuição resultante classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c99de8",
   "metadata": {
    "id": "qc-Fx5bRK_kd",
    "outputId": "9adc6802-9a27-44a1-a84e-f079bb3a9914",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataset_sample(inputs, targets):\n",
    "  # O número de elementos desejado é goal_size (isso também poderia vir por parâmetro)\n",
    "  goal_size = int(len(targets) / 3)\n",
    "\n",
    "  # Separando os ids dos elementos que pertecem à cada classe\n",
    "  classe_0_ids = np.where(targets == 0)[0]\n",
    "  classe_1_ids = np.where(targets == 1)[0]\n",
    "  tamanhos_classes = [len(x) for x in [classe_0_ids, classe_1_ids]]\n",
    "\n",
    "  # Assim como no oversample, decidimos se faremos amostragem com ou sem repetição comparando\n",
    "  # o número de elementos da classe com o objetivo. Agora queremos que cada classe tenha goal_size elementos\n",
    "  replace = False\n",
    "  if tamanhos_classes[0] < goal_size:\n",
    "    replace = True\n",
    "  classe_0_sampled_ids = np.random.choice(classe_0_ids, size=goal_size, replace=replace)\n",
    "  \n",
    "  replace = False\n",
    "  if tamanhos_classes[1] < goal_size:\n",
    "    replace = True\n",
    "  classe_1_sampled_ids = np.random.choice(classe_1_ids, size=goal_size, replace=replace)\n",
    "\n",
    "  # Até agora estávamos apenas operando nos IDs agora vamos pegar os elementos selecionados no inputs\n",
    "  dataset_sampled_data = np.concatenate([inputs[classe_0_sampled_ids],\n",
    "                                 inputs[classe_1_sampled_ids]])\n",
    "  # O mesmo para o target\n",
    "  dataset_sampled_targets = np.concatenate([targets [classe_0_sampled_ids],\n",
    "                                      targets [classe_1_sampled_ids]])\n",
    "  return dataset_sampled_data, dataset_sampled_targets\n",
    "\n",
    "dataset_sampled_data, dataset_sampled_targets = dataset_sample(inputs, targets)\n",
    "plt.hist(dataset_sampled_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9.676257,
   "end_time": "2022-10-01T12:05:06.545865",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-01T12:04:56.869608",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
